{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f41d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import requests\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391d270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions to convert USGS NAS Records into geodataframe.\n",
    "def _get_col_rename(df, dftype):\n",
    "    \"\"\"Returns a dictionary of columns to rename based on the dataframe and type('csv' or 'api')\"\"\"\n",
    "    \n",
    "    # Build a dictionary of column renamings for use in pandas rename function\n",
    "    renamed_columns = {}\n",
    "    column_names = list(df.columns)\n",
    "    lower_columns = [name.lower().replace(' ','').replace('_','') for name in column_names]\n",
    "    for i in range(len(column_names)):\n",
    "        renamed_columns[column_names[i]] = lower_columns[i]\n",
    "\n",
    "    if dftype == 'csv':\n",
    "        # build csv rename dictionary\n",
    "        renamed_columns['museumcatno'] = 'museumcatnumber'\n",
    "        renamed_columns['huc8number']  = 'huc8'\n",
    "    elif dftype == 'api':\n",
    "        # build api rename dictionary\n",
    "        renamed_columns['key']              = 'specimennumber'\n",
    "        renamed_columns['decimallatitude']  = 'latitude'\n",
    "        renamed_columns['decimallongitude'] = 'longitude'\n",
    "        renamed_columns['latlongsource']    = 'source'\n",
    "        renamed_columns['latlongaccuracy']  = 'accuracy'\n",
    "    else:\n",
    "        raise ValueError(f\"Dataframe type '{dftype}' invalid - Accepted inputs are 'csv' or 'api'\")\n",
    "\n",
    "    return renamed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b97b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions to convert USGS NAS Records into geodataframe.\n",
    "def _manage_cols(df, drop_list=[], name_dict={}):\n",
    "    \"\"\"Private method for dropping and renaming columns in a dataframe, as well as creating one standard table from two different forms.\"\"\"\n",
    "\n",
    "    for colname in drop_list:\n",
    "        if colname not in df:\n",
    "            raise ValueError(f\"Can't drop column '{colname}' - '{colname}' does not exist in dataframe\")\n",
    "    for colname in list(name_dict.keys()):\n",
    "        if colname not in df:\n",
    "            raise ValueError(f\"Can't rename '{colname}' to '{name_dict[colname]}' - '{colname}' does not exist in dataframe\")\n",
    "        if colname in drop_list:\n",
    "            raise ValueError(f\"Can't rename '{colname}' to '{name_dict[colname]}' - '{colname}' in drop_list\")\n",
    "\n",
    "    column_names = np.setdiff1d(list(df.columns), list(name_dict.keys()))\n",
    "    lower_columns = [name.lower().replace(' ','').replace('_','') for name in column_names]\n",
    "    for i in range(len(column_names)):\n",
    "        name_dict[column_names[i]] = lower_columns[i]\n",
    "    \n",
    "    df = df.drop(drop_list, axis=1)\n",
    "    df = df.rename(columns=name_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c005ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions to convert USGS NAS Records into geodataframe.\n",
    "URL_BASE = 'http://nas.er.usgs.gov/api/v2/'\n",
    "\n",
    "\n",
    "def api_df(species_id, limit, api_key):\n",
    "    \"\"\"Returns a pandas dataframe containing records about a species from the NAS database using their API\"\"\"\n",
    "    \n",
    "    # Check for API key\n",
    "    if api_key is not None:\n",
    "        url_request = f\"{URL_BASE}/occurrence/search?species_ID={species_id}&api_key={api_key}\"\n",
    "    else:\n",
    "        url_request = f\"{URL_BASE}/occurrence/search?species_ID={species_id}\"\n",
    "    \n",
    "    # Get dataframe from API request\n",
    "    request_json = requests.get(url_request, params={'limit':limit}).json()\n",
    "    api_df = pd.json_normalize(request_json, 'results')\n",
    "    api_df = _manage_cols(api_df)\n",
    "\n",
    "    # Add columns that are in a CSV dataframe but not an API dataframe\n",
    "    api_df['country']      = np.nan\n",
    "    api_df['drainagename'] = np.nan\n",
    "\n",
    "    # Rename columns\n",
    "    renamed_columns = _get_col_rename(api_df, 'api')\n",
    "    api_df = api_df.rename(columns=renamed_columns)\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = list(api_df.columns)\n",
    "    cols = cols[0:8] + cols[33:34] + cols[8:33] + cols[34:] # country\n",
    "    cols = cols[0:16] + cols[34:] + cols[16:34] # drainagename\n",
    "    api_df = api_df[cols]\n",
    "    \n",
    "    return api_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c26d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = 92\n",
    "my_state = 'Minnesota'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87238356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run API function to get records\n",
    "# Visit https://nas.er.usgs.gov/ap# Run API function to get records from NAS Database\n",
    "NAS_df = api_df(species_id = species_id, limit = 10000, api_key = {\"speciesID\": species_id})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d14158a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only columns we want \n",
    "my_data = NAS_df[[\"commonname\", \"state\", \"latitude\", \"longitude\", \"year\", \"status\", \"accuracy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c3a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data \n",
    "my_data_fltr = my_data[(my_data['status'] == 'established') & (my_data['accuracy'] == 'Accurate')\n",
    "& (my_data['state'] == 'Minnesota')]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for Present and set values for all rows to 1 \n",
    "my_data_fltr.loc[:,'Present'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your dataset\n",
    "my_data_fltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export your occurence records to your project data folder as a CSV\n",
    "my_data_fltr.to_csv(\"./data/my_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc5479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
